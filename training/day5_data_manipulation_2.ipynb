{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b5772b-fff6-41f1-91e5-3dfa4843074d",
   "metadata": {},
   "source": [
    "## Pandas: Data Manipulation II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bda313-bca6-435e-b5ac-502da48ac070",
   "metadata": {},
   "source": [
    "## Task 1: Reshaping Dataframes (Superstore Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd63d42-96a0-46fc-a3e1-5ad50c586dec",
   "metadata": {},
   "source": [
    "### 1. Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821b845a-eb1f-49b1-a809-7dea0f420e03",
   "metadata": {},
   "source": [
    "#### a) Pivot total sales by Region and Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ef637-a80d-4c54-be7e-c1679203f7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sales by Region and Category:\n",
      "Category    Furniture  Office Supplies  Technology\n",
      "Region                                            \n",
      "Central   163797.1638       167026.415  170416.312\n",
      "East      208291.2040       205516.055  264973.981\n",
      "South     117298.6840       125651.313  148771.908\n",
      "West      252612.7435       220853.249  251991.832\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/DELL/Downloads/Sample - Superstore.csv.zip', encoding='cp1252')\n",
    "\n",
    "# Create a pivot table showing total sales by Region (rows) and Category (columns)\n",
    "sales_pivot = df.pivot_table(\n",
    "    values='Sales', \n",
    "    index='Region', \n",
    "    columns='Category', \n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "print(\"Total Sales by Region and Category:\")\n",
    "print(sales_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f1520b-f604-4b02-81cb-626854d56ea9",
   "metadata": {},
   "source": [
    "#### b) Pivot average profit per Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c726c-800b-4b62-ad57-da2d61c02553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Profit by Segment and Region:\n",
      "Region         Central       East      South       West\n",
      "Segment                                                \n",
      "Consumer      7.066046  28.040153  32.116435  34.360409\n",
      "Corporate    27.791831  26.935666  29.833771  35.872323\n",
      "Home Office  28.398202  53.205611  16.987626  28.949939\n"
     ]
    }
   ],
   "source": [
    "# Create a pivot table showing average profit by Segment (rows) and Region (columns)\n",
    "profit_pivot = df.pivot_table(\n",
    "    values='Profit', \n",
    "    index='Segment', \n",
    "    columns='Region', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "print(\"\\nAverage Profit by Segment and Region:\")\n",
    "print(profit_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c2ffb3-5224-4585-8c4c-77465eec9973",
   "metadata": {},
   "source": [
    "### 2. Using melt() to unpivot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4df763-1010-4d07-b916-2524773bdb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wide Format DataFrame:\n",
      "Category   Region    Furniture  Office Supplies  Technology\n",
      "0         Central  163797.1638       167026.415  170416.312\n",
      "1            East  208291.2040       205516.055  264973.981\n",
      "2           South  117298.6840       125651.313  148771.908\n",
      "3            West  252612.7435       220853.249  251991.832\n",
      "\n",
      "Long Format DataFrame:\n",
      "     Region         Category  Total Sales\n",
      "0   Central        Furniture  163797.1638\n",
      "1      East        Furniture  208291.2040\n",
      "2     South        Furniture  117298.6840\n",
      "3      West        Furniture  252612.7435\n",
      "4   Central  Office Supplies  167026.4150\n",
      "5      East  Office Supplies  205516.0550\n",
      "6     South  Office Supplies  125651.3130\n",
      "7      West  Office Supplies  220853.2490\n",
      "8   Central       Technology  170416.3120\n",
      "9      East       Technology  264973.9810\n",
      "10    South       Technology  148771.9080\n",
      "11     West       Technology  251991.8320\n"
     ]
    }
   ],
   "source": [
    "# First create a wide format dataframe (sales by region and category)\n",
    "wide_df = df.pivot_table(\n",
    "    values='Sales', \n",
    "    index='Region', \n",
    "    columns='Category', \n",
    "    aggfunc='sum'\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nWide Format DataFrame:\")\n",
    "print(wide_df)\n",
    "\n",
    "# Now melt it back to long format\n",
    "long_df = wide_df.melt(\n",
    "    id_vars='Region',\n",
    "    value_vars=['Furniture', 'Office Supplies', 'Technology'],\n",
    "    var_name='Category',\n",
    "    value_name='Total Sales'\n",
    ")\n",
    "\n",
    "print(\"\\nLong Format DataFrame:\")\n",
    "print(long_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a2ce2-ec1d-4d2f-94c2-d30a3e63c616",
   "metadata": {},
   "source": [
    "## Task 2: Apply Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf7cde-bb93-4ad9-8af6-033005116206",
   "metadata": {},
   "source": [
    "### 1. Classifying Profit Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06369cf-1ea6-4077-935f-92d128b53a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Profit Margin Classification Distribution:\n",
      "Margin Class\n",
      "High      5898\n",
      "Loss      1871\n",
      "Low       1291\n",
      "Medium     934\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate profit margin (Profit/Sales)\n",
    "df['Profit Margin'] = df['Profit'] / df['Sales']\n",
    "\n",
    "# Define a function to classify profit margins\n",
    "def classify_margin(margin):\n",
    "    if margin > 0.2:  # 20% margin\n",
    "        return 'High'\n",
    "    elif margin > 0.1:  # 10-20% margin\n",
    "        return 'Medium'\n",
    "    elif margin >= 0:\n",
    "        return 'Low'\n",
    "    else:\n",
    "        return 'Loss'  # Negative margin\n",
    "\n",
    "# Apply the classification using lambda\n",
    "df['Margin Class'] = df['Profit Margin'].apply(lambda x: classify_margin(x))\n",
    "\n",
    "# Show distribution\n",
    "print(\"\\nProfit Margin Classification Distribution:\")\n",
    "print(df['Margin Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b9790-3d02-427a-bde7-6e711dd09c3b",
   "metadata": {},
   "source": [
    "### 2. Flagging Rows Based on Discount Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11f9fa-fc69-4c76-a5a0-326225c141e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discount Flag Distribution:\n",
      "Discount Flag\n",
      "Normal    8041\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Discount Flag'] = df['Discount'].apply(lambda x: 'High Discount' if x > 0.9 else 'Normal')\n",
    "\n",
    "print(\"\\nDiscount Flag Distribution:\")\n",
    "print(df['Discount Flag'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42dd1e-bf67-4839-b45f-2aa3cfcde032",
   "metadata": {},
   "source": [
    "## Task 3: Mapping & Replacing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf49ba-d594-404d-a1b6-834bd809342f",
   "metadata": {},
   "source": [
    "### 1. Mapping Full Country Names to Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12670360-c0a6-4723-a730-0ad122feeed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State abbreviations added:\n",
      "        State State Abbr\n",
      "0    Kentucky         KY\n",
      "1    Kentucky         KY\n",
      "2  California         CA\n",
      "3     Florida         FL\n",
      "4     Florida         FL\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping dictionary for US states\n",
    "state_to_abbr = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR',\n",
    "    'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE',\n",
    "    'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID',\n",
    "    'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS',\n",
    "    'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n",
    "    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY',\n",
    "    'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT',\n",
    "    'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI', 'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "# Create a new column with state abbreviations\n",
    "df['State Abbr'] = df['State'].map(state_to_abbr)\n",
    "\n",
    "# Show the first few rows to verify\n",
    "print(\"\\nState abbreviations added:\")\n",
    "print(df[['State', 'State Abbr']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941960b6-90b1-48e2-b3e3-3a47bf74ea5a",
   "metadata": {},
   "source": [
    "### 2. Replacing \"Consumer\" with \"Retail\" in Segment Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba071eb-5dd7-42d6-8d3a-eccaf3d9bf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segment values after replacement:\n",
      "Segment\n",
      "Retail         5191\n",
      "Corporate      3020\n",
      "Home Office    1783\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace values in the Segment column\n",
    "df['Segment'] = df['Segment'].replace({'Consumer': 'Retail'})\n",
    "\n",
    "# Verify the replacement\n",
    "print(\"\\nSegment values after replacement:\")\n",
    "print(df['Segment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f73c4-3d69-4354-8964-169ad21814b4",
   "metadata": {},
   "source": [
    "## Task 4: Combining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beedad00-3f57-49d4-9fc3-9f73cc02a90c",
   "metadata": {},
   "source": [
    "### 1. Vertical Concatenation (axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ec16e-c593-4d5d-b1b2-33fdab6ebf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (9994, 25)\n",
      "Combined shape: (9994, 25)\n",
      "Original and combined row counts match: True\n"
     ]
    }
   ],
   "source": [
    "# Split the DataFrame into two parts\n",
    "df1 = df.iloc[:5000]  # First 5000 rows\n",
    "df2 = df.iloc[5000:]  # Remaining rows\n",
    "\n",
    "# Vertical concatenation (stacking rows)\n",
    "vertical_combined = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Combined shape: {vertical_combined.shape}\")\n",
    "print(\"Original and combined row counts match:\", len(df) == len(vertical_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3164454-4e4f-4ebd-88ef-cb4408aa8043",
   "metadata": {},
   "source": [
    "### 2. Horizontal Concatenation (axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d29f5-0809-4f10-bd96-89f3ddb95e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original columns: 25\n",
      "Combined columns: 8\n"
     ]
    }
   ],
   "source": [
    "# Split columns into two DataFrames\n",
    "df_cols1 = df[['Row ID', 'Order ID', 'Order Date', 'Ship Date']]\n",
    "df_cols2 = df[['Ship Mode', 'Customer ID', 'Customer Name', 'Segment']]\n",
    "\n",
    "# Horizontal concatenation (side-by-side)\n",
    "horizontal_combined = pd.concat([df_cols1, df_cols2], axis=1)\n",
    "\n",
    "print(\"\\nOriginal columns:\", df.shape[1])\n",
    "print(\"Combined columns:\", horizontal_combined.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f79bd7-2a31-4a55-afe3-86d4de9a0fb7",
   "metadata": {},
   "source": [
    "### 3. Combining DataFrames with Mismatched Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd796e1-f36e-414c-8cf5-6693b6d688c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame A columns: ['Order ID', 'Customer ID', 'Sales']\n",
      "DataFrame B columns: ['Order ID', 'Product ID', 'Profit']\n",
      "Combined DataFrame columns: ['Order ID', 'Customer ID', 'Sales', 'Product ID', 'Profit']\n",
      "\n",
      "Combined DataFrame sample:\n",
      "         Order ID Customer ID     Sales Product ID  Profit\n",
      "0  CA-2014-158337    KA-16525  108.9200        NaN     NaN\n",
      "1  CA-2014-124688    CC-12610   29.1200        NaN     NaN\n",
      "2  US-2016-146794    SH-19975  424.9575        NaN     NaN\n",
      "3  US-2017-118087    SP-20620    4.6720        NaN     NaN\n",
      "4  CA-2015-152891    TB-21625  253.1760        NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# Create two DataFrames with some overlapping and some unique columns\n",
    "df_a = df[['Order ID', 'Customer ID', 'Sales']].sample(n=1000)\n",
    "df_b = df[['Order ID', 'Product ID', 'Profit']].sample(n=1000)\n",
    "\n",
    "# Concatenate with mismatched columns\n",
    "combined_mismatched = pd.concat([df_a, df_b], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"\\nDataFrame A columns:\", df_a.columns.tolist())\n",
    "print(\"DataFrame B columns:\", df_b.columns.tolist())\n",
    "print(\"Combined DataFrame columns:\", combined_mismatched.columns.tolist())\n",
    "print(\"\\nCombined DataFrame sample:\")\n",
    "print(combined_mismatched.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c83486-2924-4cce-a8d3-762b720e6f39",
   "metadata": {},
   "source": [
    "### 4. Handling Overlapping Data with Different Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42161d0-63e7-4b56-a463-d1fc2e696bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined overlapping DataFrames (sample):\n",
      "                  Sales  Discount\n",
      "Order ID                         \n",
      "CA-2017-161851   15.570       NaN\n",
      "CA-2015-157434    7.968       NaN\n",
      "CA-2017-135909  209.940       NaN\n",
      "US-2016-125402   10.900       NaN\n",
      "CA-2017-111269  479.952       NaN\n"
     ]
    }
   ],
   "source": [
    "# Create two DataFrames with overlapping Order IDs but different data\n",
    "df_overlap1 = df[['Order ID', 'Sales']].drop_duplicates(subset=['Order ID']).sample(n=1000)\n",
    "df_overlap2 = df[['Order ID', 'Discount']].drop_duplicates(subset=['Order ID']).sample(n=1000)\n",
    "\n",
    "# Combine them horizontally\n",
    "combined_overlap = pd.concat([df_overlap1.set_index('Order ID'), \n",
    "                            df_overlap2.set_index('Order ID')], axis=1)\n",
    "\n",
    "print(\"\\nCombined overlapping DataFrames (sample):\")\n",
    "print(combined_overlap.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266564d-0ab0-4afe-bb9f-a873b5d61691",
   "metadata": {},
   "source": [
    "## Task 5: Superstore Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347343be-b047-4af2-9698-1a886eb23bc4",
   "metadata": {},
   "source": [
    "### Step 1: Load raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2da4255-0e51-4ff2-8add-e5ce4abebc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data shape: (9994, 21)\n",
      "First few rows:\n",
      "   Row ID        Order ID Order Date   Ship Date     Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156  11/8/2016  11/11/2016  Second Class    CG-12520   \n",
      "1       2  CA-2016-152156  11/8/2016  11/11/2016  Second Class    CG-12520   \n",
      "2       3  CA-2016-138688  6/12/2016   6/16/2016  Second Class    DV-13045   \n",
      "\n",
      "     Customer Name    Segment        Country         City  ... Postal Code  \\\n",
      "0      Claire Gute   Consumer  United States    Henderson  ...       42420   \n",
      "1      Claire Gute   Consumer  United States    Henderson  ...       42420   \n",
      "2  Darrin Van Huff  Corporate  United States  Los Angeles  ...       90036   \n",
      "\n",
      "   Region       Product ID         Category Sub-Category  \\\n",
      "0   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "\n",
      "                                        Product Name   Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.96         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.94         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.62         2   \n",
      "\n",
      "   Discount    Profit  \n",
      "0       0.0   41.9136  \n",
      "1       0.0  219.5820  \n",
      "2       0.0    6.8714  \n",
      "\n",
      "[3 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/DELL/Downloads/Sample - Superstore.csv.zip', encoding='cp1252')\n",
    "\n",
    "print(f\"Raw data shape: {df.shape}\")\n",
    "print(\"First few rows:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc7c309-141d-4124-a383-b9a01f41a962",
   "metadata": {},
   "source": [
    "### Step 2: Clean and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93efb7-e604-4165-86ff-a326c8ba1d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Cleaning and filtering data...\n",
      "Cleaned data shape: (8041, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 2: Cleaning and filtering data...\")\n",
    "\n",
    "# Data cleaning\n",
    "# Convert date columns to datetime\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "df['Ship Date'] = pd.to_datetime(df['Ship Date'])\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Filter data - remove negative profits and outliers\n",
    "df = df[df['Profit'] >= 0]\n",
    "df = df[df['Sales'] < df['Sales'].quantile(0.99)]  # Remove top 1% sales outliers\n",
    "\n",
    "# Standardize categorical values\n",
    "df['Segment'] = df['Segment'].replace({'Consumer': 'Retail'})\n",
    "df['Category'] = df['Category'].str.title()\n",
    "\n",
    "print(f\"Cleaned data shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beef7d6-e497-4982-abf3-b450b935ad55",
   "metadata": {},
   "source": [
    "### Step 3: Group and Reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32f665-7301-4c50-b210-9de82d16d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Grouping and reshaping data...\n",
      "Grouped data sample:\n",
      "    Region   Category     Ship Mode     Sales     Profit  Quantity  \\\n",
      "0  Central  Furniture   First Class   4531.26   918.5455  3.750000   \n",
      "1  Central  Furniture      Same Day   3812.52   900.6535  3.583333   \n",
      "2  Central  Furniture  Second Class  10626.98  2510.4912  3.640000   \n",
      "\n",
      "   Profit Margin  \n",
      "0       0.202713  \n",
      "1       0.236236  \n",
      "2       0.236238  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 3: Grouping and reshaping data...\")\n",
    "\n",
    "# Create a grouped summary\n",
    "grouped = df.groupby(['Region', 'Category', 'Ship Mode']).agg({\n",
    "    'Sales': 'sum',\n",
    "    'Profit': 'sum',\n",
    "    'Quantity': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Add a profit margin column\n",
    "grouped['Profit Margin'] = grouped['Profit'] / grouped['Sales']\n",
    "\n",
    "print(\"Grouped data sample:\")\n",
    "print(grouped.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442b78df-3a10-46f5-9696-8ec9ebad775b",
   "metadata": {},
   "source": [
    "### Step 4: Add Derived Column Using .apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60260b57-4d6e-40dd-bf89-f08777be1186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Adding derived columns...\n",
      "Derived columns added:\n",
      "    Region         Category  Profit Margin    Performance Tier\n",
      "0  Central        Furniture       0.202713  Medium Performance\n",
      "1  Central        Furniture       0.236236  Medium Performance\n",
      "2  Central        Furniture       0.236238  Medium Performance\n",
      "3  Central        Furniture       0.207703  Medium Performance\n",
      "4  Central  Office Supplies       0.280611    High Performance\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 4: Adding derived columns...\")\n",
    "\n",
    "# Categorize shipping efficiency (days between order and ship)\n",
    "def shipping_efficiency(row):\n",
    "    days = (row['Ship Date'] - row['Order Date']).days\n",
    "    if days == 0:\n",
    "        return 'Same Day'\n",
    "    elif days <= 2:\n",
    "        return 'Fast'\n",
    "    elif days <= 5:\n",
    "        return 'Standard'\n",
    "    else:\n",
    "        return 'Slow'\n",
    "\n",
    "df['Shipping Efficiency'] = df.apply(shipping_efficiency, axis=1)\n",
    "\n",
    "# Performance tier based on profit margin\n",
    "def performance_tier(margin):\n",
    "    if margin > 0.25:\n",
    "        return 'High Performance'\n",
    "    elif margin > 0.15:\n",
    "        return 'Medium Performance'\n",
    "    elif margin > 0:\n",
    "        return 'Low Performance'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "grouped['Performance Tier'] = grouped['Profit Margin'].apply(performance_tier)\n",
    "\n",
    "print(\"Derived columns added:\")\n",
    "print(grouped[['Region', 'Category', 'Profit Margin', 'Performance Tier']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ff690-2e85-40dd-b311-ec650e8cd90b",
   "metadata": {},
   "source": [
    "### Step 5: Pivot for a summary dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1344b4be-d353-4970-be3a-3033a78ba037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Creating pivot tables for dashboard...\n",
      "\n",
      "Profit by Category & Region:\n",
      "Region              Central         East       South         West        Total\n",
      "Category                                                                      \n",
      "Furniture        14296.9977   18779.2915  15946.8229   22568.2872   71591.3993\n",
      "Office Supplies  28293.3123   44644.0475  23897.9050   50157.0671  146992.3319\n",
      "Technology       24373.8656   36760.4717  18743.2121   34151.7574  114029.3068\n",
      "Total            66964.1756  100183.8107  58587.9400  106877.1117  332613.0380\n",
      "\n",
      "Shipping Efficiency Distribution:\n",
      "Region               Central  East  South  West\n",
      "Shipping Efficiency                            \n",
      "Fast                     221   386    232   542\n",
      "Same Day                  82   120     71   147\n",
      "Slow                     311   417    234   524\n",
      "Standard                 954  1345    811  1644\n",
      "\n",
      "Performance Tier Summary:\n",
      "Category              Furniture  Office Supplies  Technology           All\n",
      "Performance Tier                                                          \n",
      "High Performance            NaN       500290.143  150959.802  6.512499e+05\n",
      "Low Performance     178622.3475              NaN    5746.016  1.843684e+05\n",
      "Medium Performance  246618.7400        29816.458  351969.822  6.284050e+05\n",
      "All                 425241.0875       530106.601  508675.640  1.464023e+06\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 5: Creating pivot tables for dashboard...\")\n",
    "\n",
    "# Pivot 1: Profit by Category & Region\n",
    "profit_pivot = pd.pivot_table(\n",
    "    data=grouped,\n",
    "    values='Profit',\n",
    "    index='Category',\n",
    "    columns='Region',\n",
    "    aggfunc='sum',\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "# Pivot 2: Shipping Efficiency by Region\n",
    "shipping_pivot = pd.pivot_table(\n",
    "    data=df,\n",
    "    values='Sales',\n",
    "    index='Shipping Efficiency',\n",
    "    columns='Region',\n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Pivot 3: Performance Tier Summary\n",
    "performance_pivot = grouped.pivot_table(\n",
    "    values='Sales',\n",
    "    index='Performance Tier',\n",
    "    columns='Category',\n",
    "    aggfunc='sum',\n",
    "    margins=True\n",
    ")\n",
    "\n",
    "print(\"\\nProfit by Category & Region:\")\n",
    "print(profit_pivot)\n",
    "\n",
    "print(\"\\nShipping Efficiency Distribution:\")\n",
    "print(shipping_pivot)\n",
    "\n",
    "print(\"\\nPerformance Tier Summary:\")\n",
    "print(performance_pivot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
